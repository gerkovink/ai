[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI developments in higher education",
    "section": "",
    "text": "Preface\nThis is an archive of the generative AI developments in higher education that I have come across. The main aim of this archive is to create a structured overview of developments, policies and studies on implementing and regulating AI in higher education.\nNo parts of this resource have been generated with AI. All parts of this resource may be used and shared freely, also within AI tools, with the exception of model training. Do not use this resource for further training of generative AI models.\nFeel free to contribute.\nAll the best,\nGerko",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Aim\nThe aim of this archive is not to be exhaustive, but rather to provide a structure whereby to categorize past, new and ongoing developments.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#contributions",
    "href": "intro.html#contributions",
    "title": "1  Introduction",
    "section": "1.2 Contributions",
    "text": "1.2 Contributions\nI very much welcome contributions to this page. If you have come across a development, policy or study that is not yet included in this archive, please let me know, or rather, add it yourself. Follow the below outline to see how easy it is to propose changes and additions to this archive.\n\n\n\nExample change commit and pull request\n\n\nI do ask you, however, to not generate your contributed text with AI. I prefer this resources to remain a human-curated archive.\n\n\n\n\nTuring, Alan. 2004. “Lecture on the Automatic Computing Engine (1947).” In The Essential Turing. Oxford University Press. https://doi.org/10.1093/oso/9780198250791.003.0015.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Commun. ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "legal.html",
    "href": "legal.html",
    "title": "4  Legal implications",
    "section": "",
    "text": "4.1 How to read this chapter",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "legal.html#data-protection-and-privacy",
    "href": "legal.html#data-protection-and-privacy",
    "title": "4  Legal implications",
    "section": "4.2 Data protection and privacy",
    "text": "4.2 Data protection and privacy",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "legal.html#intellectual-property",
    "href": "legal.html#intellectual-property",
    "title": "4  Legal implications",
    "section": "4.3 Intellectual property",
    "text": "4.3 Intellectual property\nSee e.g. this book chapter from Vink, Veen, and Oberman (2024)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "legal.html#copyright",
    "href": "legal.html#copyright",
    "title": "4  Legal implications",
    "section": "4.4 Copyright",
    "text": "4.4 Copyright\nSee e.g. this book chapter from Vink, Veen, and Oberman (2024)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "legal.html#europes-ai-act",
    "href": "legal.html#europes-ai-act",
    "title": "4  Legal implications",
    "section": "4.5 Europe’s AI act",
    "text": "4.5 Europe’s AI act",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "legal.html#ethics",
    "href": "legal.html#ethics",
    "title": "4  Legal implications",
    "section": "4.6 Ethics",
    "text": "4.6 Ethics\nPerhaps this should be its own chapter and not a subheading under Chapter 4.\n\n\n\n\nVink, Gerko, Duco Veen, and Hanne Oberman. 2024. “gerkovink/openeducationbook: Open Education in Higher Education.” Zenodo. https://doi.org/10.5281/zenodo.10594358.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Legal implications</span>"
    ]
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "10  Collection of links",
    "section": "",
    "text": "10.1 Responsibility and conscience",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "links.html#responsibility-and-conscience",
    "href": "links.html#responsibility-and-conscience",
    "title": "10  Collection of links",
    "section": "",
    "text": "There is evidence that the workers who curate these models are treated unfairly or even inhumanely by their employers. This interview from March 25 also outlines how and where AI moderation can harm the people who don’t have a voice.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "links.html#assessment-given-the-existence-of-ai-tools",
    "href": "links.html#assessment-given-the-existence-of-ai-tools",
    "title": "10  Collection of links",
    "section": "10.2 Assessment given the existence of AI tools",
    "text": "10.2 Assessment given the existence of AI tools\nSome links (in no particular order) that cover relevant strategies on how to assess student work, given the existence of AI tools.\n\nUCL: Designing assessments in and AI enabled world\nUNF: ChatGPT-proof your course\nUU: Can you still use take-home exams and essays?\nBower, M., Torrington, J., Lai, J.W.M. et al. (2024) How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey. Educ Inf Technol.\nTILAPIA tool by Phil Newton & ChatGPT\n\n\n10.2.1 Scientific publications\n\nDo teachers spot AI?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "links.html#policy",
    "href": "links.html#policy",
    "title": "10  Collection of links",
    "section": "10.3 Policy",
    "text": "10.3 Policy\n\n10.3.1 Guidelines for students\n\nUMCU: Guidelines for GSLS students\nUMCU: GenAI guidelines for research projects for students and supervisors\n\n\n\n10.3.2 Guidelines for teachers\n\nUMCU: Guidelines for Incorporating Generative AI (GenAI) in GSLS Education\n\n\n\n10.3.3 Policy\n\nUNESCO: Guidance for generative AI in education and research\nWEF: AI Guidance for responsible use in education\nColumbia University\nDuke University\n(Chan 2023)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "links.html#ai-skills",
    "href": "links.html#ai-skills",
    "title": "10  Collection of links",
    "section": "10.4 AI skills",
    "text": "10.4 AI skills\n\nUMCU: AI skills tutorial for GSLS master students\nUMCU: AI skills tutorial for GSLS master teachers",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "links.html#ai-for-grading-student-work",
    "href": "links.html#ai-for-grading-student-work",
    "title": "10  Collection of links",
    "section": "10.5 AI for grading student work",
    "text": "10.5 AI for grading student work\n\nMy presentation on the use and misuse of generative AI in academic education\nKumar (2023)\n\n\n\n\n\nChan, Cecilia Ka Yuk. 2023. “A Comprehensive AI Policy Education Framework for University Teaching and Learning.” International Journal of Educational Technology in Higher Education 20 (1): 38.\n\n\nKumar, Rahul. 2023. “Faculty Members’ Use of Artificial Intelligence to Grade Student Papers: A Case of Implications.” International Journal for Educational Integrity 19 (1): 9.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Collection of links</span>"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "2  How genAI tools work",
    "section": "",
    "text": "2.1 Machine learning basics\nMachine learning enables computers to learn from data, identify patterns, and make decisions with varying levels of human intervention. For understanding this chapter, it is important to realize that some machine learning methods require quite strict human intervention or data pre-processing, while other methods can operate unsupervised and without stringent data pre-processing.\nIt is also important to understand that machine learning methods often work by means of training. An algorithm is trained to perform a single task or set of tasks. For example, a machine learning model can be trained on thousands of images to differentiate between photos of children or adults. Much like our own brain would learn to differentiate between such images.\nThe domain of machine learning that focuses on such human brain-like deep learning strategies is called neural networks (NNs). NNs consist of layers of units (so called neurons) that process input data. NNs are not specifically programmed to perform tasks, yet NNs process data in such a way that they autonomously learn to perform those tasks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>How genAI tools work</span>"
    ]
  },
  {
    "objectID": "models.html#transformers",
    "href": "models.html#transformers",
    "title": "2  How genAI tools work",
    "section": "2.2 Transformers",
    "text": "2.2 Transformers\nTransformers (Vaswani et al. 2017) are a type of neural network that have advanced deep learning, particularly in the domain of natural language processing. Instead of modeling words one after another, transformers can look at whole sentences or paragraphs at once and take the context of text into account. It is not hard to imagine that contextual understanding allows for better learning and more flexible applications.\nGenerative AI tools, such as Gemini, chatGPT or GitHub Copilot are applications of transformers. These tools have been trained on extremely large amounts of data (mostly text) and have learned from the structure, meaning and nuances of the language. After training, these tools can generate new text that both coherent an contextually relevant. All this generation is based on the patterns the transformers learned during training.\nThere is a bit more nuance to the above two paragraph than I would initially have you believe. First, there are two mechanisms crucial in a transformer’s ability to understand the nuance and context of language: attention and self-attention. In a nutshell, these mechanisms allow the transformer to weigh the importance of words in the context, which creates a measure of the immediate and broader relations of each word. Second, the training step is far more complex than described above. There is a lot of fine-tuning involved. Additionally, for different purposes like programming code generation or visual image recognition, models must undergo additional training or finetuning with specific data sets. This makes the training of contemporary AI tools a time-consuming and human-curated task.\nContemporary AI tools can do much more than predict the next most likely word based on a given prompt or initial input. Modern AI tools can interpret images, read and solve mathematical formulae, start up virtual machines to autonomously evaluate self-generated computer code, and much more. Given the relatively recent introduction of transformers, this seamless integration of applications, skills and tasks is an impressive development.\n\n\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” Advances in Neural Information Processing Systems 30.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>How genAI tools work</span>"
    ]
  },
  {
    "objectID": "policy.html",
    "href": "policy.html",
    "title": "5  Policy",
    "section": "",
    "text": "5.1 Durably embedding generative AI in academia\nThe following policy suggestion ensures that generative AI is implemented in an academic setting by means of human moderation. It places the user in control of responsible interaction with the AI tool and warrants conscientious further implementation of the output generated by the AI tool. The suggestions clearly separate both input and output of tools, since both are easily prone to misuse. Following the suggestions below minimizes the opportunity for unlawful, unethical and unfair use of AI tools in academia.\nSuggestion 1: Minimize the use of AI tools as they are (currently) environmentally unfriendly\nMany users are unaware of the impact that contemporary AI tools may have on the environment. Together with e]’g. cloud storage and e-mail traffic, AI tools constitute a hidden carbon footprint that often escapes our awareness. While it is not as apparent as airline travel, the impact of using AI tools may be far greater than you think (Berthelot et al. 2024). While the environmental impact may be significantly lowered by on-chip generative AI , there will always be a cost of using AI tools. Many people have thought about how AI will impact human life and Hollywood has monetized its threat to human existence. Not many may have realized that our lives may be at risk through AI-induced global warming.\nSuggestion 2: Don’t input confidential or personal information\nThis may seem intuitive, but the ability of AI tools to mimic human-like interaction may lull the user into the situation of disclosing more information than allowed. It is not hard to imagine a scenario where a well-engineered prompt would allow for the identification of the person who interacts with the AI tool, or worse - other people that are not aware of their personal ideas or identifying information being disclosed. While the AI tool itself seems anonymous and may not be sentient, any user should be aware of potential information or attribute disclosure.\nSuggestion 3: Don’t input information that violates IP or copyright\nWhen interacting with AI tools, users should protect intellectual property rights and copyright. When submitting prompts to AI tools it is paramount to ensure that\nSuggestion 4: Don’t violate IP with using output from the tool\nLikewise, it is paramount to realize that no intellectual property or copyright may be infringed with using the output of the AI tool. The training of the AI tool happened on a large set of data; some of that data may have been used illegitimately. By using AI generated output you may plagiarize existing work or otherwise infringe on intellectual property rights.\nThis is a tricky scenario, as the nontransparent training of AI tools makes it challenging to prove that no IP is infringed with the realized output. Given that the other suggestions are not violated, however, one could argue that embedding AI tools in a normal scientific knowledge discovery scenario would minimize the change of any infringement. Such a route would result in a process where information from multiple sources is processed and curated by an actual human.\nSuggestion 5: Confirm the output accuracy\nNever put all your eggs in one basket. AI tools have demonstrated to yield inaccurate, incomplete or false information. This can happen when the AI tool perceives patterns or objects that are nonexistent, resulting in nonsensical or inaccurate output, often referred to as hallucinations (Ji et al. 2023; Alkaissi and McFarlane 2023; Athaluri et al. 2023), although some resistance against that term has emerged (Østergaard and Nielbo 2023). It is important to always use multiple sources to verify any bit of information. As a user of AI tools you should accept that only you are responsible for using, interpreting and curating AI-generated output.\nSuggestion 6: Check the tool output for bias\nAI tools are prone to biased output due to the language and bias that are incorporated int he training resource Bockting et al. (2023). AI tools may therefore produce output that may impact real humans and their rights, identifications, characteristics or status. Be careful not to input promts that are likely to generate biased output and do not use AI-generated output if potential bias may occur.\nSuggestion 7: Don’t do bad or illegal things with AI tools\nNever use AI tools for illegal purposes or malicious intent, such as creating viruses, hacking networks or any form of computer crime or other crime.\nSuggestion 8: Disclose the use of AI tools in your work Always disclose the use of AI tools, also when the work you generated is derived from AI-generated output. Always be transparent about your work.\nSuggestion 9: Ask the tool not to use input for training As a safety precaution it may be good practice to prevent further training of the models from input data. This avoids risks of accidentally disclosing information that should not have been send as input.\nSuggestion 10: Open the content you produce by using AI tools as much as possible with permissive licenses. Opening up your research is a good practice in general.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "policy.html#durably-embedding-generative-ai-in-academia",
    "href": "policy.html#durably-embedding-generative-ai-in-academia",
    "title": "5  Policy",
    "section": "",
    "text": "you are allowed to share the information in the prompt or have explicit permission\nyou are not infringing on any right associated with the information in the prompt",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "policy.html#why-are-these-suggestions-necessary",
    "href": "policy.html#why-are-these-suggestions-necessary",
    "title": "5  Policy",
    "section": "5.2 Why are these suggestions necessary?",
    "text": "5.2 Why are these suggestions necessary?\nUser interaction with AI tools may seem as an anonymous and private encounter, but it is far from that. The possibility of uploading materials to and interacting with a seemingly human-like tool in the privacy of the own home may lull the user into a false sense of security. Kumar (2023) illustrates this wonderfully in a case study of a hypothetical professor. When your interaction with an AI tool feels secure, sharing private or rights-protected materials may seem inconsequential, but such practice is nonetheless unlawful. At the same time it is not realistic to forbid any generative AI interaction in academia: Knowledge advancement and experimentation are foundations of scientific practice. For academic institutions it is therefore very important to have a policy in place that allows for human-moderated use of AI tools, such that they can be embedded in a normal scientific evidence-based workflow. I believe that the same policy should apply to faculty and students to ensure a common community-driven conscientious implementation and application of human&lt;-&gt;AI interaction, much in the same way as we implement and broadcast good scientific conduct.\n\n\n\n\nAlkaissi, Hussam, and Samy I McFarlane. 2023. “Artificial Hallucinations in ChatGPT: Implications in Scientific Writing.” Cureus 15 (2).\n\n\nAthaluri, Sai Anirudh, Sandeep Varma Manthena, VSR Krishna Manoj Kesapragada, Vineel Yarlagadda, Tirth Dave, and Rama Tulasi Siri Duddumpudi. 2023. “Exploring the Boundaries of Reality: Investigating the Phenomenon of Artificial Intelligence Hallucination in Scientific Writing Through ChatGPT References.” Cureus 15 (4).\n\n\nBerthelot, Adrien, Eddy Caron, Mathilde Jay, and Laurent Lefèvre. 2024. “Estimating the environmental impact of Generative-AI services using an LCA-based methodology.” In CIRP LCE 2024 - 31st Conference on Life Cycle Engineering, 1–10. Turin, Italy. https://inria.hal.science/hal-04346102.\n\n\nBockting, Claudi, Eva A Dis, Robert Rooij, Willem Zuidema, and Johan Bollen. 2023. “Living Guidelines for Generative AI — Why Scientists Must Oversee Its Use.” Nature 622 (October): 693–96. https://doi.org/10.1038/d41586-023-03266-1.\n\n\nDuin, Ann Hill, and Isabel Pedersen. 2021. Writing Futures: Collaborative, Algorithmic, Autonomous. Springer.\n\n\nJi, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. “Survey of Hallucination in Natural Language Generation.” ACM Comput. Surv. 55 (12). https://doi.org/10.1145/3571730.\n\n\nKumar, Rahul. 2023. “Faculty Members’ Use of Artificial Intelligence to Grade Student Papers: A Case of Implications.” International Journal for Educational Integrity 19 (1): 9.\n\n\nØstergaard, Søren Dinesen, and Kristoffer Laigaard Nielbo. 2023. “False Responses From Artificial Intelligence Models Are Not Hallucinations.” Schizophrenia Bulletin 49 (5): 1105–7. https://doi.org/10.1093/schbul/sbad068.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "students.html",
    "href": "students.html",
    "title": "7  For students",
    "section": "",
    "text": "For now, see Chapter 10.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>For students</span>"
    ]
  },
  {
    "objectID": "teachers.html",
    "href": "teachers.html",
    "title": "8  For teachers",
    "section": "",
    "text": "For now, see Chapter 10.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>For teachers</span>"
    ]
  },
  {
    "objectID": "assessment.html",
    "href": "assessment.html",
    "title": "9  Grading and Assessment",
    "section": "",
    "text": "For now, see Chapter 10.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Grading and Assessment</span>"
    ]
  },
  {
    "objectID": "skills.html",
    "href": "skills.html",
    "title": "6  AI skills",
    "section": "",
    "text": "For now, see Chapter 10.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>AI skills</span>"
    ]
  }
]